<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Immersive Cognition (ICON) Lab Group - University of Leeds - Projects Homepage ">

    <title>Human-Like Computing - Immersive Cognition (ICON)</title>

    
    <meta name="description" content="A project aiming to investigate the potential of human-like approaches in computation and robotics problems.">  
    <meta name="og:title" property="og:title" content="Human-Like Computing">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400i,700i|Work+Sans:400" rel="stylesheet">
    <link rel="icon" type="image/png" sizes="48x48" href="/static/favicon.png">
    <link rel="stylesheet" href="/static/styles.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-3P5HDZ8GRW"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-3P5HDZ8GRW');
    </script>
</head>

<body>
    <div id="main">
        <div class="greyed">
            <div class="inner-body">
                <div id="navbar">
                    <ul class="navlist">
                        <a class="logo" href="/">
                            <img class="logo" src="/static/logo.png" />
                        </a>
                        <a href="/projects">
                            <li>Projects</li>
                        </a>
                        <a href="/papers">
                            <li>Papers</li>
                        </a>
                        <a href="/people">
                            <li>People</li>
                        </a>
                        <a href="/contact">
                            <li>Contact</li>
                        </a>
                    </ul>

                    <ul class="navlist navlist-right">
                        <a href="https://twitter.com/ICON_UoL" title="Twitter">
                            <li><i class="fab fa-twitter twitter-color"></i></li>
                        </a>
                        <a href="http://github.com/immersivecognition" title="GitHub">
                            <li><i class="fab fa-github github-color"></i></li>
                        </a>
                    </ul>
                </div>
            </div>
        </div>
        <div class="inner-body footer-spacer">
            <div id="content">
                

<div class="section post">
    <div class="post-sidebar">
        
        <img width=100 height=100 src="/static/project-images/hlc.png" />
        
        <h1>Human-Like Computing</h1>

        <ul class="me-links">
            
            
            <span class="link-title">Website</span>
            <li>
                <a href="https://github.com/m-hasan-n/hlp">
                    <i class="fas fa-external-link-alt link-color"></i>
                    External link
                </a>
            </li>
            
        </ul>

    </div><div class="post-main">
        <h1>Human-Like Computing (HLC)</h1>

<h2>Background</h2>

<p>How do you grasp a bottle of milk, nestling behind some yoghurt pots, within a cluttered fridge. Humans are able to easily and rapidly plan such actions using visual information, while robots struggle.
While artificial intelligence has made great leaps in beating humans in tasks such as chess, the planning and execution abilities of today's robots are trumped by the average toddler.
Given the complex and unpredictable world we live in, these apparently trivial tasks are the product of highly sophisticated neural computations that generalise and adapt to changing situations: continually engaged in a process of selecting between multiple goals and actions.</p>

<p>Our aim is to investigate how such computations could be transferred to robots to enable them to manipulate objects more efficiently, in a ore human-like way than is presently the case, and to be able to perform manipulation presently beyond the state of the art.</p>

<h2>Implementation</h2>

<p>To investigate how humans interact with cluttered environments, a virtual reality (VR) scenario was created. 
VR has many advantages over traditional experimental setups, elaborated on in the UXF project. 
The Unity game engine and UXF were used to create a scenario where participants move obstacles on a table to reach a target and retrieve it to an end point.
The participant's hand, elbow and shoulder were tracked using a HTC Vive VR system and 2x HTC Vive trackers.
See the video below for an example of the scenario:</p>

<p><video controls>
  <source src="/static/files/cluttered-environment-task.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<p>Experimental data was collected for 20 participants, each performing 120 trials where we manipulated the setup of the obstacles to investigate certain behaviours. 
In conjunction with the data collection, a computational model was created to describe a high level process by which humans could select which obstacles to move given a layout, which works on assessing where the gaps between obstacles are and whether the participant needs to interact with obstacles to give a useable path to the target.</p>

<p>Read the full <a href="https://ieeexplore.ieee.org/abstract/document/9196665">paper</a> on Human-Like Computing in the 2020 IEEE International Conference on Robotics and Automation (ICRA)!</p>

    </div>

</div>



            </div>

            <div id="footer">
                Copyright Immersive Cognition 2021
            </div>
        </div>
    </div>
</body>

</html>